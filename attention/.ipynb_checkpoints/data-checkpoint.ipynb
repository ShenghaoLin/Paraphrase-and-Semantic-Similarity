{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from random import random\n",
    "import sys\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "device = torch.device(0 if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from train/test data files and return the tuple as (label, original_sent, candsent, trendid)\n",
    "def readInData(filename):\n",
    "\n",
    "    data = []\n",
    "    trends = set([])\n",
    "    \n",
    "    (trendid, trendname, origsent, candsent, judge, origsenttag, candsenttag) = (None, None, None, None, None, None, None)\n",
    "    \n",
    "    for line in open(filename):\n",
    "        line = line.strip()\n",
    "        #read in training or dev data with labels\n",
    "        if len(line.split('\\t')) == 7:\n",
    "            (trendid, trendname, origsent, candsent, judge, origsenttag, candsenttag) = line.split('\\t')\n",
    "        #read in test data without labels\n",
    "        elif len(line.split('\\t')) == 6:\n",
    "            (trendid, trendname, origsent, candsent, origsenttag, candsenttag) = line.split('\\t')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        #if origsent == candsent:\n",
    "        #    continue\n",
    "        \n",
    "        trends.add(trendid)\n",
    "        \n",
    "        if judge == None:\n",
    "            data.append((judge, origsent, candsent, trendid))\n",
    "            continue\n",
    "\n",
    "        # ignoring the training/test data that has middle label \n",
    "        if judge[0] == '(':  # labelled by Amazon Mechanical Turk in format like \"(2,3)\"\n",
    "            nYes = eval(judge)[0]\n",
    "            data.append((nYes/5, origsent, candsent, trendid))\n",
    "        elif judge[0].isdigit():   # labelled by expert in format like \"2\"\n",
    "            nYes = int(judge[0])\n",
    "            data.append((nYes/5, origsent, candsent, trendid))   \n",
    "                \n",
    "    return data, trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dict(embedding_path, d_model):\n",
    "    d = {}\n",
    "    embedding_list = []\n",
    "    with open(embedding_path, 'r', encoding='utf-8') as f:\n",
    "        line = f.readline()\n",
    "        idx = 1\n",
    "        while line:\n",
    "            try:\n",
    "                k = line.split()\n",
    "                a = [float(w) for w in k[1:]]\n",
    "                if (len(a)==d_model):\n",
    "                    d[k[0].lower()] = idx\n",
    "                    idx += 1\n",
    "                    embedding_list.append(a)\n",
    "            except:\n",
    "                pass\n",
    "            line = f.readline()\n",
    "    tmp = []\n",
    "    for i in range(d_model):\n",
    "        tmp.append(0)\n",
    "    embedding_list = [tmp] + embedding_list\n",
    "    embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_list), padding_idx=0)\n",
    "\n",
    "    print('Reading embedding finished.')\n",
    "        \n",
    "    return d, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(x, max_len=10000):\n",
    "#     max_len = 0\n",
    "#     for xx in x:\n",
    "#         if max_len < len(xx):\n",
    "#             max_len = len(xx)\n",
    "    for i in range(len(x)):\n",
    "        xx = x[i]\n",
    "        kk = len(xx)\n",
    "        x[i] = xx + ([0] * (max_len - kk)) \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(d, sentence):\n",
    "    s=sentence.strip().split()\n",
    "    for i in range(len(s)):\n",
    "        s[i]=s[i].lower()\n",
    "        if s[i] in d.keys():\n",
    "            s[i]=d[s[i]]\n",
    "        else:\n",
    "            s[i]=0\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(embedding_path, input_path, testing=False, d_model=200, max_len=None):\n",
    "    d, embedding = generate_dict(embedding_path, d_model)\n",
    "    x0 = []\n",
    "    x1 = []\n",
    "    y = []\n",
    "    trends, _ = readInData(input_path)\n",
    "\n",
    "    for trend in trends:\n",
    "        if testing:\n",
    "            x0.append(get_index(d, trend[1]))\n",
    "            x1.append(get_index(d, trend[2]))\n",
    "            y.append(-1)\n",
    "        else:\n",
    "            x0.append(get_index(d, trend[1]))\n",
    "            x1.append(get_index(d, trend[2]))\n",
    "            y.append(trend[0])\n",
    "    \n",
    "    if max_len==None:\n",
    "        max_len = 0\n",
    "        for xx in x0 + x1:\n",
    "            if max_len < len(xx):\n",
    "                max_len = len(xx)\n",
    "    print(\"max length is: \", max_len)\n",
    "    embedding=embedding.to(device)\n",
    "    x0 = embedding(torch.tensor(padding(x0, max_len=max_len)).to(device))    \n",
    "    x1 = embedding(torch.tensor(padding(x1, max_len=max_len)).to(device))    \n",
    "\n",
    "    return x0.cpu(), x1.cpu(), torch.tensor(y, dtype=torch.float), embedding.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_PATH = '../tmp/attention_model'\n",
    "\n",
    "# Data & embedding configerations\n",
    "d_model = 50\n",
    "PRE_TRAINED_EMBEDDING_PATH = '../embedding/glove.twitter.27B.'+str(d_model)+'d.txt'\n",
    "DATA_PATH = '../data/train.data'\n",
    "OUTPUT_PATH = '../data/train_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading embedding finished.\n",
      "max length is:  18\n"
     ]
    }
   ],
   "source": [
    "x0, x1, Y, emb = preprocessing(PRE_TRAINED_EMBEDDING_PATH, DATA_PATH, testing=False, d_model=d_model, max_len=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([972, 18, 200])\n",
      "torch.Size([972, 18, 200])\n",
      "torch.Size([972])\n",
      "tensor([3, 2, 2, 1, 1, 4, 1, 2, 3, 3, 2, 4, 1, 1, 3, 3, 4, 2, 1, 1, 1, 3, 2, 2,\n",
      "        2, 3, 4, 4, 4, 2, 3, 2, 3, 4, 2, 3, 3, 1, 1, 3, 1, 1, 1, 3, 1, 3, 2, 4,\n",
      "        3, 2, 5, 2, 5, 2, 3, 3, 1, 5, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 1,\n",
      "        1, 3, 1, 2, 3, 3, 1, 3, 2, 4, 3, 1, 1, 1, 2, 1, 3, 2, 1, 4, 1, 3, 1, 2,\n",
      "        2, 2, 2, 4, 3, 5, 4, 1, 2, 1, 1, 4, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 1, 2, 1, 1, 1, 1, 1, 4, 2, 5, 1, 1, 4, 2, 1, 3, 1, 1, 1, 1, 2,\n",
      "        5, 3, 2, 2, 4, 3, 5, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 4, 3, 4,\n",
      "        3, 2, 1, 0, 0, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 3, 3, 1, 3, 3, 3, 1, 1, 2, 1, 2, 3, 1, 1, 1, 2, 1,\n",
      "        2, 2, 1, 1, 2, 4, 4, 4, 1, 1, 4, 1, 4, 4, 1, 4, 3, 5, 5, 3, 1, 1, 5, 3,\n",
      "        3, 2, 2, 4, 4, 1, 5, 3, 5, 1, 3, 1, 1, 4, 4, 3, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 2, 5, 3, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 2, 1, 1, 1, 1, 1, 1, 2, 3, 2, 2, 2, 2,\n",
      "        1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 3, 2, 2, 1, 2, 1, 1, 1, 1,\n",
      "        1, 1, 1, 2, 1, 1, 2, 5, 4, 4, 4, 5, 3, 5, 2, 3, 4, 5, 2, 4, 4, 4, 5, 4,\n",
      "        5, 5, 5, 4, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 4, 5, 4, 4, 4, 4, 4,\n",
      "        4, 1, 2, 1, 5, 1, 1, 1, 4, 1, 1, 4, 1, 3, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 3, 1, 1, 4, 1, 3, 1, 1, 4, 3, 4, 3, 1, 2, 3, 2, 1, 3, 3, 1, 1, 2,\n",
      "        1, 1, 5, 3, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 3, 1, 0, 2, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 1, 3, 2, 1, 2, 2, 2, 2, 3, 1, 4, 2, 2, 3, 1, 3,\n",
      "        3, 1, 1, 1, 3, 4, 3, 3, 2, 4, 4, 3, 3, 3, 4, 3, 4, 4, 5, 3, 4, 4, 5, 4,\n",
      "        3, 2, 3, 3, 5, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 5, 4, 1, 2, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 3, 4, 4, 3, 2, 2, 3, 2, 1, 1, 1, 3, 1,\n",
      "        1, 1, 1, 3, 2, 1, 2, 4, 2, 1, 1, 1, 1, 5, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 4, 1, 4, 3, 3, 4, 4, 3, 4, 4, 4, 5, 1, 4, 4, 4, 5, 4, 4, 4,\n",
      "        3, 1, 4, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 2, 1, 1, 1, 3, 3, 3, 3, 3, 1, 5, 4, 4, 2, 2, 4, 4, 4, 4, 4, 3, 4,\n",
      "        3, 2, 2, 2, 4, 4, 3, 1, 4, 1, 3, 1, 1, 1, 1, 3, 3, 4, 4, 1, 1, 5, 1, 4,\n",
      "        5, 3, 1, 1, 1, 1, 3, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 4, 4, 1, 2, 2, 2, 3, 2, 2, 1, 1,\n",
      "        4, 4, 4, 3, 5, 3, 4, 4, 1, 2, 1, 3, 2, 1, 3, 1, 1, 1, 3, 1, 3, 2, 1, 1,\n",
      "        3, 3, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 5, 4, 4, 2, 3, 3,\n",
      "        3, 5, 3, 4, 1, 1, 1, 4, 5, 4, 4, 0, 4, 4, 4, 1, 4, 1, 2, 3, 1, 3, 1, 1,\n",
      "        3, 1, 1, 3, 3, 4, 1, 1, 4, 4, 2, 4, 4, 0, 0, 0, 0, 0, 0, 3, 2, 2, 1, 1,\n",
      "        2, 1, 2, 2, 3, 1, 0, 0, 0, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1,\n",
      "        1, 1, 2, 3, 3, 2, 1, 3, 4, 4, 2, 3, 1, 1, 5, 4, 4, 3, 4, 1, 1, 2, 1, 1,\n",
      "        3, 2, 2, 4, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x0.size())\n",
    "print(x1.size())\n",
    "print(Y.size())\n",
    "Y=Y.long()\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(OUTPUT_PATH+\"_\"+str(d_model)+\"d_reg.pkl\", \"wb\")\n",
    "pickle.dump(x0, f)\n",
    "pickle.dump(x1, f)\n",
    "pickle.dump(Y, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
