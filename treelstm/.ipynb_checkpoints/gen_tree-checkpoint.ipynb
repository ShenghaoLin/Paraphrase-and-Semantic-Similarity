{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "from random import random\n",
    "import sys\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "device = torch.device(0 if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, idx):\n",
    "        self.parent = None\n",
    "        self.num_children = 0\n",
    "        self.children = list()\n",
    "        self.index = idx\n",
    "        self.state = None\n",
    "\n",
    "    def add_child(self, child):\n",
    "        child.parent = self\n",
    "        self.num_children += 1\n",
    "        self.children.append(child)\n",
    "\n",
    "    def size(self):\n",
    "        if getattr(self, '_size'):\n",
    "            return self._size\n",
    "        count = 1\n",
    "        for i in range(self.num_children):\n",
    "            count += self.children[i].size()\n",
    "        self._size = count\n",
    "        return self._size\n",
    "\n",
    "    def depth(self):\n",
    "        if getattr(self, '_depth'):\n",
    "            return self._depth\n",
    "        count = 0\n",
    "        if self.num_children > 0:\n",
    "            for i in range(self.num_children):\n",
    "                child_depth = self.children[i].depth()\n",
    "                if child_depth > count:\n",
    "                    count = child_depth\n",
    "            count += 1\n",
    "        self._depth = count\n",
    "        return self._depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read from train/test data files and return the tuple as (label, original_sent, candsent, trendid)\n",
    "def readInData(filename):\n",
    "\n",
    "    data = []\n",
    "    trends = set([])\n",
    "    \n",
    "    (trendid, trendname, origsent, candsent, judge, origsenttag, candsenttag) = (None, None, None, None, None, None, None)\n",
    "    \n",
    "    for line in open(filename):\n",
    "        line = line.strip()\n",
    "        #read in training or dev data with labels\n",
    "        if len(line.split('\\t')) == 7:\n",
    "            (trendid, trendname, origsent, candsent, judge, origsenttag, candsenttag) = line.split('\\t')\n",
    "        #read in test data without labels\n",
    "        elif len(line.split('\\t')) == 6:\n",
    "            (trendid, trendname, origsent, candsent, origsenttag, candsenttag) = line.split('\\t')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        #if origsent == candsent:\n",
    "        #    continue\n",
    "        \n",
    "        trends.add(trendid)\n",
    "        \n",
    "        if judge == None:\n",
    "            data.append((judge, origsenttag, candsenttag, trendid))\n",
    "            continue\n",
    "\n",
    "        # ignoring the training/test data that has middle label \n",
    "        if judge[0] == '(':  # labelled by Amazon Mechanical Turk in format like \"(2,3)\"\n",
    "            nYes = eval(judge)[0]\n",
    "            data.append((nYes, origsenttag, candsenttag, trendid))\n",
    "        elif judge[0].isdigit():   # labelled by expert in format like \"2\"\n",
    "            nYes = int(judge[0])\n",
    "            data.append((nYes, origsenttag, candsenttag, trendid))        \n",
    "                \n",
    "    return data, trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dict(embedding_path, d_model):\n",
    "    d = {}\n",
    "    embedding_list = []\n",
    "    with open(embedding_path, 'r', encoding='utf-8') as f:\n",
    "        line = f.readline()\n",
    "        idx = 1\n",
    "        while line:\n",
    "            try:\n",
    "                k = line.split()\n",
    "                a = [float(w) for w in k[1:]]\n",
    "                if (len(a)==d_model):\n",
    "                    d[k[0].lower()] = idx\n",
    "                    idx += 1\n",
    "                    embedding_list.append(a)\n",
    "            except:\n",
    "                pass\n",
    "            line = f.readline()\n",
    "    tmp = []\n",
    "    for i in range(d_model):\n",
    "        tmp.append(0)\n",
    "    embedding_list = [tmp] + embedding_list\n",
    "    embedding = nn.Embedding.from_pretrained(torch.tensor(embedding_list), padding_idx=0)\n",
    "\n",
    "    print('Reading embedding finished.')\n",
    "        \n",
    "    return d, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding(x, max_len=10000):\n",
    "#     max_len = 0\n",
    "#     for xx in x:\n",
    "#         if max_len < len(xx):\n",
    "#             max_len = len(xx)\n",
    "    for i in range(len(x)):\n",
    "        xx = x[i]\n",
    "        kk = len(xx)\n",
    "        x[i] = xx + ([0] * (max_len - kk)) \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tree(d, sentence):\n",
    "    s=sentence.strip().split()\n",
    "    temp=[]\n",
    "    for i in range(len(s)):\n",
    "        s[i]=s[i].lower()\n",
    "        s[i]=s[i].split('/')\n",
    "        cur_node = Tree(i)\n",
    "        \n",
    "        word=s[i][0]\n",
    "        s0=s[i][1]\n",
    "        s1=s[i][3]\n",
    "        if s0[0]=='b':\n",
    "            temp.append(Tree(-1))\n",
    "            temp[-1].add_child(cur_node)\n",
    "        elif s0[0]=='i':\n",
    "            temp[-1].add_child(cur_node)\n",
    "        else:\n",
    "            if s1[0]=='b':\n",
    "                temp.append(Tree(-1))\n",
    "                temp[-1].add_child(cur_node)\n",
    "            elif (s1[0]=='i'):\n",
    "                temp[-1].add_child(cur_node)\n",
    "            else:\n",
    "                temp.append(cur_node)\n",
    "\n",
    "        if word in d.keys():\n",
    "            s[i]=d[word]\n",
    "        else:\n",
    "            s[i]=0\n",
    "            \n",
    "    root = Tree(-1)\n",
    "    for child in temp:\n",
    "        root.add_child(child)\n",
    "    \n",
    "    return s, root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(embedding_path, input_path, testing=False, d_model=200, max_len=None):\n",
    "    d, embedding = generate_dict(embedding_path, d_model)\n",
    "    x0 = []\n",
    "    x0_r = []\n",
    "    x1 = []\n",
    "    x1_r = []\n",
    "    y = []\n",
    "    trends, _ = readInData(input_path)\n",
    "\n",
    "    for trend in trends:\n",
    "        if testing:\n",
    "            s, r = generate_tree(d, trend[1])\n",
    "            x0.append(s)\n",
    "            x0_r.append(r)\n",
    "            s, r = generate_tree(d, trend[2])\n",
    "            x1.append(s)\n",
    "            x1_r.append(r)\n",
    "            y.append(-1)\n",
    "        else:\n",
    "            s, r = generate_tree(d, trend[1])\n",
    "            x0.append(s)\n",
    "            x0_r.append(r)\n",
    "            s, r = generate_tree(d, trend[2])\n",
    "            x1.append(s)\n",
    "            x1_r.append(r)\n",
    "            y.append(trend[0])\n",
    "    \n",
    "    if max_len==None:\n",
    "        max_len = 0\n",
    "        for xx in x0 + x1:\n",
    "            if max_len < len(xx):\n",
    "                max_len = len(xx)\n",
    "    print(\"max length is: \", max_len)\n",
    "    embedding=embedding.to(device)\n",
    "    x0 = embedding(torch.tensor(padding(x0, max_len=max_len)).to(device))    \n",
    "    x1 = embedding(torch.tensor(padding(x1, max_len=max_len)).to(device))    \n",
    "\n",
    "    return x0.cpu(), x1.cpu(), torch.tensor(y, dtype=torch.float), x0_r, x1_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data & embedding configerations\n",
    "d_model = 50\n",
    "PRE_TRAINED_EMBEDDING_PATH = '../embedding/glove.twitter.27B.'+str(d_model)+'d.txt'\n",
    "DATA_PATH = '../data/test.data'\n",
    "OUTPUT_PATH = '../data/test_data_tree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading embedding finished.\n",
      "max length is:  18\n"
     ]
    }
   ],
   "source": [
    "x0, x1, Y, x0_r, x1_r = preprocessing(PRE_TRAINED_EMBEDDING_PATH, DATA_PATH, testing=False, d_model=d_model, max_len=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=open(OUTPUT_PATH+\"_\"+str(d_model)+\"d.pkl\", \"wb\")\n",
    "pickle.dump(x0, f)\n",
    "pickle.dump(x1, f)\n",
    "pickle.dump(Y, f)\n",
    "pickle.dump(x0_r, f)\n",
    "pickle.dump(x1_r, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
